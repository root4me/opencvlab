/*
 * gesture.cpp
 *
 *  Created on: Jun 21, 2015
 *      Author: harish
 */

#include <opencv2/imgcodecs.hpp>
#include <opencv2/videoio/videoio.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/video.hpp>

#include <iostream>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>


bool verbose = false;
int camera = -1;

using namespace std;
using namespace cv;

Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor

int capturevideo()
{
	VideoCapture capture(camera);

	int n = 0;
	char filename[200];
	string window_name = "video | q or esc to quit";
	cout << "press space to save a picture. q or esc to quit" << endl;
	namedWindow(window_name, WINDOW_KEEPRATIO); //resizable window;
	Mat frame;

	for (;;) {
		capture >> frame;
		if (frame.empty())
			break;

		imshow(window_name, frame);
		char key = (char)waitKey(30); //delay N millis, usually long enough to display and capture input

		switch (key) {
		case 'q':
		case 'Q':
		case 27: //escape key
			return 0;
		case ' ': //Save an image
			sprintf(filename,"filename%.3d.jpg",n++);
			imwrite(filename,frame);
			cout << "Saved " << filename << endl;
			break;
		default:
			break;
		}
	}
	return 0;
}


/*
 * Take in a frame and apply background subtraction algorithm on it
 */
Mat backSubT(Mat& frame)
{
	Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method

	pMOG2->apply(frame, fgMaskMOG2);

	imshow("FG Mask MOG 2", fgMaskMOG2);

	return fgMaskMOG2;
}

/*
 * Take in a frame and apply canny edge
 */

Mat canny(Mat& frame)
{
	Mat src_gray, detected_edges, afterCanny,afterContours;
	Scalar color;

	vector<vector<Point> > contours;

	cvtColor( frame, src_gray, CV_BGR2GRAY );
	blur( src_gray, detected_edges, cv::Size(3,3) );

	// canny
	Canny(detected_edges, afterCanny, 10, 10 * 3);

	//imshow("After Canny", afterCanny);

	findContours(afterCanny, contours, RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);

	/// Draw contours
	afterContours = Mat::zeros(afterCanny.size(), CV_8UC3);
	color = Scalar(0, 180, 0);
	drawContours(afterContours, contours, -1, color, 1, 8);
	imshow("After canny - Contour", afterContours);

	return afterCanny;
}

Mat blurThreshold(Mat& frame)
{
	Mat src_gray,src_blurred,src_thresh;

	cvtColor( frame, src_gray, CV_BGR2GRAY );
	GaussianBlur(src_gray,src_blurred, Size(5,5),0,0);
	/* 0: Binary
     1: Binary Inverted
     2: Threshold Truncated
     3: Threshold to Zero
     4: Threshold to Zero Inverted
	 */
	threshold(src_blurred,src_thresh,70,255,1);

	imshow("After blur and tresh", src_thresh);

	return src_thresh;
}

Mat hsvThreashold(Mat& frame)
{
	Mat src_blurred;
	//GaussianBlur(frame,src_blurred, Size(3,3),0,0);

	Mat src_hsv;
	cvtColor(frame,src_hsv,CV_BGR2HSV);

	Mat src_hsvrange;
	inRange(src_hsv, Scalar(0,10,60), Scalar(20,150,255), src_hsvrange);

	imshow("After hsv convert range", src_hsvrange);

	erode( src_hsvrange, src_hsvrange, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );
	//dilate( src_hsvrange, src_hsvrange, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );

	//erode(src_hsvrange,src_hsvrange,Mat(),Point(-1,-1));
	//dilate(src_hsvrange, src_hsvrange, Mat(), Point(-1,-1),2);

	return src_hsvrange;
}

Mat hsvBackProjection(Mat& frame)
{
	Mat hsvframe, hue;
	cvtColor(frame,hsvframe,CV_BGR2HSV);
	hue.create( hsvframe.size(), hsvframe.depth() );
	int ch[] = {0, 0};
	mixChannels(&hsvframe, 1, &hue, 1, ch, 1);

	string window_image = "Source image";

	return hue;
}

void getGesture(const Mat& frame)
{

	vector<vector<Point> > contours;

	findContours(frame, contours, RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);

	Mat afterContours;

	//	convexHull(Mat(points), hull, true);

	Rect roi;
	Point2f center;
	float radius;

	vector<Point> hull;
	vector<int> hullInt;
	vector<vector<Point> > hulls;
	vector<Vec4i> defects;

	for (int i=0; i< contours.size(); i++)
	{
		if (contourArea(contours[i]) > 20000)
		{
			//cout << contourArea(contours[i]) << endl;

			afterContours = Mat::zeros(frame.size(), CV_8UC3);
			drawContours(afterContours, contours, i, Scalar(0, 180, 0), 1, 8);

			roi = boundingRect(contours[i]);

			rectangle(afterContours,roi,Scalar(0, 180, 0), 1, 8);

			// get the convex hull
			convexHull(Mat(contours[i]), hull,true, true);
			convexHull(Mat(contours[i]), hullInt,true, false);

			hulls.push_back(hull);

			//get the center
			minEnclosingCircle(hull, center, radius);
			//mark the center
			circle(afterContours, center, cvRound(10), Scalar(0, 255, 255), 1, LINE_4);

			//assuming only one hull for now
			drawContours(afterContours, hulls, 0, Scalar(0, 180, 0), 1, 8);

			//find the hull defect points and mark
			convexityDefects(contours[i], hullInt, defects);
			for (int j=0; j < defects.size() ; j++)
			{
				//cout << "defect : " << defects[j] << endl;
				Vec4i d = defects[j];

				int faridx=d[0];
				Point ptFar(contours[i][defects[j][0]]);// the farthest from the convex hull point within the defect

				//cout << defects[j][3]/256.0 << endl;
				if(defects[j][3] > 5000)
				{
					circle(afterContours,Point (contours[i][defects[j][0]]), cvRound(5), Scalar(0, 0, 180), 1, LINE_4);
					circle(afterContours,Point (contours[i][defects[j][1]]), cvRound(5), Scalar(255, 0, 0), 1, LINE_4);
					circle(afterContours,Point (contours[i][defects[j][2]]), cvRound(5), Scalar(0, 255, 0), 1, LINE_4);
				}
			}

			//cout<<"Rectangle " <<i<< " Centroid position is at: " << center.x << " " << center.y << endl;

			imshow("After hsv - Contour", afterContours);

		}
	}

}

bool train = false;
bool trained = false;
bool captureRoi = false;
Rect trainRoi;
Mat hsv, mask, hue, hist;
int hsize = 16;
float hranges[] = {0,180};
const float* phranges = hranges;

int captureVideo(int& cam)
{

	cout << cam << endl;

	VideoCapture cap(cam);

	Mat frame;

	if(!cap.isOpened())
	{
		cout << "problem !" << endl;
		return -1;
	}

	namedWindow("Camera",1);
	for(;;)
	{

		char c = (char)waitKey(10);
		if( c == 27 )
			break;

		switch(c)
		{
		case 't':
			train = !train;
			cout << train << endl;
			break;
		case ' ':
			if (train)
			{
				captureRoi = true;
			}
			break;
		default:
			;
		}

		cap >> frame;

		/* from camshift.cpp */
		cvtColor(frame, hsv, COLOR_BGR2HSV);
		inRange(hsv, Scalar(0, 30, MIN(10,256)), Scalar(180, 256, MAX(10, 256)), mask);
		int ch[] = {0, 0};
		hue.create(hsv.size(), hsv.depth());
		mixChannels(&hsv, 1, &hue, 1, ch, 1);

		if (train)
		{
			trainRoi.x = frame.cols/3;
			trainRoi.y = frame.rows/3;
			trainRoi.height = (frame.rows/3);
			trainRoi.width = (frame.cols/3);

			if (!(captureRoi))
			{
				Mat roi(frame, trainRoi);
				bitwise_not(roi, roi);
			}
			else // generate histogram for selection
			{
				train = !train;
				captureRoi = !captureRoi;

				cout << "capture" << endl;

				Mat roi(hue, trainRoi), maskroi(mask, trainRoi);
				calcHist(&roi, 1, 0, maskroi, hist, 1, &hsize, &phranges);
				normalize(hist, hist, 0, 255, NORM_MINMAX);

				cout << hist << endl;
				trained = true;

			}
		}
		else
		{
			/// Get Backprojection
			if (trained)
			{
				Mat backproj;
				calcBackProject( &hue, 1, 0, hist, backproj, &phranges, 1, true );

				//dilate( backproj, backproj, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );
				//erode( backproj, backproj, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );

				/// Draw the backproj
				imshow( "BackProj", backproj );

				getGesture(backproj);


			}

			//backSubT(frame);
			//canny(frame);
			//getGesture(hsvThreashold(frame));
			//blurThreshold(frame);
		}

		imshow("Camera", frame);
	}

	return 0;
}

void printusage()
{
	cout << "usage : gesture [-v] [-c <camera number>] " << endl;
	cout << "\t-v	Display verbose output. Used to output debug values to console" << endl;
	cout << "\t-c	Specify camera 0 or 1. If there is only one cam it is usually 0. Any additional USB cams will have higher numbers" << endl;
}


int main(int argc, char **argv) {

	int option;
	char *cam;

	if (argc ==1 ) printusage();

	while ((option = getopt (argc, argv, "c:v")) != -1)
	{
		switch (option)
		{
		case 'c':
			cam = optarg;
			camera = atoi(cam); // convert to integer
			cout << "capture from camera " << camera << endl;
			break;
		case 'v':
			verbose = true;
			break;
		default:
			printusage();
			return 1;

		}
	}

	pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach


	return captureVideo(camera);
}
